{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model for Whailing Wall Identification**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Load Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_Whailing_Wall = pd.read_csv('LiwenliangSample_Whailing_Wall.csv')\n",
    "sample_Whailing_Wall['Whailing Wall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling: \n",
      " 0    1881\n",
      "1    1881\n",
      "Name: Whailing Wall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(sample_Whailing_Wall['è¯„è®ºå†…å®¹'].to_frame(), sample_Whailing_Wall['Whailing Wall'])\n",
    "# summarize class distribution\n",
    "print(\"After undersampling: \\n\", y_under.value_counts())\n",
    "\n",
    "df_whailing_wall = pd.concat([X_under,y_under],axis=1)\n",
    "df_whailing_wall.rename(columns={'è¯„è®ºå†…å®¹':'sentence','Whailing Wall':'label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>åŸ‹å¤´äº‹ä¸šä¾¿ä»¤å¤§å®¶å¥½è¿‡</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>è¿™ä¸ªå¯æ€•çš„2020è¦è¿‡å»äº†ï¼</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021å¹´ï¼Œè¦å¥½å¥½ç…§é¡¾è‡ªå·±ï¼Œè¦è®¤è®¤çœŸçœŸ å¯¹å¾…æ¯ä¸€åˆ†é’Ÿï¼Œæ¯ä¸€å¤©~</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æœ‰çš„äººçœŸçš„ä¸é…å½“æ¯äº²</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>åˆå“­äº†çœ‹æ¥æˆ‘è¦å“­å¤Ÿäº†å¿ƒæƒ…æ‰å¥½å›æ¥</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>ä½ å¹å“¨äº†ï¼Œä½†æœ‰äº›å°±æ˜¯å¬ä¸å…¥è€³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>ææ–‡äº®å…ƒæ—¦å¿«ä¹ æ„¿ä½ åœ¨å¤©å›½å®‰å¥½ ï¼</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>è‡´æ•¬â¤ï¸</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>æåŒ»ç”Ÿï¼Œä¸€ç™¾å¤©äº†ã€‚ç¥æ‚¨å®‰å¥½ã€‚æˆ‘ä»Šå¤©æ—©ç¡ï¼æ™šå®‰</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>ä¸ä¼šå¿˜è®°æ‚¨ï¼Œæ„¿æ‚¨å®‰æ¯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3762 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence  label\n",
       "0                          åŸ‹å¤´äº‹ä¸šä¾¿ä»¤å¤§å®¶å¥½è¿‡      0\n",
       "1                      è¿™ä¸ªå¯æ€•çš„2020è¦è¿‡å»äº†ï¼      0\n",
       "2     2021å¹´ï¼Œè¦å¥½å¥½ç…§é¡¾è‡ªå·±ï¼Œè¦è®¤è®¤çœŸçœŸ å¯¹å¾…æ¯ä¸€åˆ†é’Ÿï¼Œæ¯ä¸€å¤©~      0\n",
       "3                          æœ‰çš„äººçœŸçš„ä¸é…å½“æ¯äº²      0\n",
       "4                    åˆå“­äº†çœ‹æ¥æˆ‘è¦å“­å¤Ÿäº†å¿ƒæƒ…æ‰å¥½å›æ¥      0\n",
       "...                               ...    ...\n",
       "3757                   ä½ å¹å“¨äº†ï¼Œä½†æœ‰äº›å°±æ˜¯å¬ä¸å…¥è€³      1\n",
       "3758                ææ–‡äº®å…ƒæ—¦å¿«ä¹ æ„¿ä½ åœ¨å¤©å›½å®‰å¥½ ï¼      1\n",
       "3759                             è‡´æ•¬â¤ï¸      1\n",
       "3760           æåŒ»ç”Ÿï¼Œä¸€ç™¾å¤©äº†ã€‚ç¥æ‚¨å®‰å¥½ã€‚æˆ‘ä»Šå¤©æ—©ç¡ï¼æ™šå®‰      1\n",
       "3761                       ä¸ä¼šå¿˜è®°æ‚¨ï¼Œæ„¿æ‚¨å®‰æ¯      1\n",
       "\n",
       "[3762 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whailing_wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_whailing_wall.sentence.values\n",
    "labels = df_whailing_wall.label.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Adding Codebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Whaling Wall</th>\n",
       "      <th>Tree Hole</th>\n",
       "      <th>Not Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å¤©å ‚</td>\n",
       "      <td>çƒ¦</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>æåŒ»ç”Ÿ</td>\n",
       "      <td>ä»Šå¤©</td>\n",
       "      <td>å›¾ç‰‡è¯„è®º</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ä½ </td>\n",
       "      <td>è‡ªå·±</td>\n",
       "      <td>å›¾ç‰‡è¯„è®º  ç½‘é¡µé“¾æ¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æ‚¨</td>\n",
       "      <td>å¤©æ°”</td>\n",
       "      <td>ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>è‹±é›„</td>\n",
       "      <td>æ˜å¤©</td>\n",
       "      <td>çœ‹çœ‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>è®ºæ–‡</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ä¿ä½‘</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>å¤‡è€ƒ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ä½œä¸š</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>å´©æºƒ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Whaling Wall Tree Hole Not Related\n",
       "0             å¤©å ‚         çƒ¦         NaN\n",
       "1            æåŒ»ç”Ÿ        ä»Šå¤©        å›¾ç‰‡è¯„è®º\n",
       "2              ä½         è‡ªå·±  å›¾ç‰‡è¯„è®º  ç½‘é¡µé“¾æ¥\n",
       "3              æ‚¨        å¤©æ°”           ã€‚\n",
       "4             è‹±é›„        æ˜å¤©          çœ‹çœ‹\n",
       "..           ...       ...         ...\n",
       "119          NaN        è®ºæ–‡         NaN\n",
       "120          NaN        ä¿ä½‘         NaN\n",
       "121          NaN        å¤‡è€ƒ         NaN\n",
       "122          NaN        ä½œä¸š         NaN\n",
       "123          NaN        å´©æºƒ         NaN\n",
       "\n",
       "[124 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook = pd.read_csv('codebook.csv')\n",
    "codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å¤©å ‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>æåŒ»ç”Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ä½ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æ‚¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>è‹±é›„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>å­¦é•¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>æå…„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>æ°‘æ—è‹±é›„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>æ•¬ç¤¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ç¼…æ€€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code\n",
       "0     å¤©å ‚\n",
       "1    æåŒ»ç”Ÿ\n",
       "2      ä½ \n",
       "3      æ‚¨\n",
       "4     è‹±é›„\n",
       "..   ...\n",
       "86    å­¦é•¿\n",
       "87    æå…„\n",
       "88  æ°‘æ—è‹±é›„\n",
       "89    æ•¬ç¤¼\n",
       "90    ç¼…æ€€\n",
       "\n",
       "[91 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook_whaling_wall = pd.DataFrame(data=codebook['Whaling Wall'].unique(),columns=['code'])\n",
    "codebook_whaling_wall.dropna(inplace=True)\n",
    "codebook_whaling_wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å¤©å ‚', 'æåŒ»ç”Ÿ', 'ä½ ', 'æ‚¨', 'è‹±é›„', 'è‡´æ•¬', 'è°¢è°¢', 'æ„Ÿè°¢', 'æ–‡äº®', 'äº®å“¥', 'æå“¥', 'ä¸€è·¯èµ°å¥½', 'å®‰å¥½', 'RIP', 'è°¢è°¢æ‚¨', 'ğŸ™ğŸ»', 'ğŸ™', 'æŠ¢æ•‘', 'æ°¸è¿œè®°å¾—', 'é“­è®°', '[å°ç™½èŠ]', 'å®‰æ¯', 'æè€å¸ˆ', 'çƒˆå£«', 'åœ¨é‚£è¾¹', 'ğŸ’', '[è Ÿç‡­]', 'å¹å“¨äºº', 'èµ°å¥½', 'ç”Ÿæ—¥å¿«ä¹', 'è¿˜å¥½å—', 'è€æ', 'æ­å–œ', 'ä¸ä¼šå¿˜è®°', 'æ°¸å‚ä¸æœ½', 'å¥½ä¹…ä¸è§', 'æ–‡äº®è€å“¥', 'åº†ä½™å¹´2', 'ç¥ˆç¥·', 'å†è§', 'æ‚¨å®¶äºº', 'R.I.P', 'åŠ æ²¹', 'è°ƒæŸ¥', 'è¿Ÿåˆ°çš„æ­£ä¹‰', 'æå¤§å¤«', 'é—å¿˜', 'æ€€å¿µ', 'è®­è¯«ä¹¦', 'å¤©ä½¿', 'æ”¾å¿ƒ', 'å…ˆç”Ÿ', 'åƒå¤', 'åº†ä½™å¹´', 'å¥‡è¿¹', 'æ°¸è¿œ', 'é’å¹´', 'å…¬é“', 'æ²¡æœ‰å¿˜è®°', 'å¹³å®‰å›æ¥', 'è¾Ÿè°£', 'ğŸ•¯ï¸', 'å‹‡æ•¢çš„äºº', 'ä½ çš„å®¶äºº', 'æ‚¨çš„å®¶äºº', 'ä¿é‡', 'æƒ³åˆ°ä½ ', 'å¥½ä¹…æ²¡æ¥', 'å›æ¥', 'å®‰', 'æé†«å¸«', 'å¸ˆå…„', 'çœ‹çœ‹ä½ ', 'è¡¨å½°', 'ç¥å¥½', '2.6', 'æsir', 'ä¼Ÿå¤§', 'äº®äº®', 'å¹³è¡Œä¸–ç•Œ', 'æ‚¼å¿µ', 'è®°å¾—ä½ ', 'å½“çˆ¸çˆ¸', 'ç­‰ä½ ', 'æ´»è¿‡æ¥', 'è¾›è‹¦äº†', 'å­¦é•¿', 'æå…„', 'æ°‘æ—è‹±é›„', 'æ•¬ç¤¼', 'ç¼…æ€€']\n"
     ]
    }
   ],
   "source": [
    "new_tokens = []\n",
    "for i in (codebook_whaling_wall['code']):\n",
    "    new_tokens.append(i)\n",
    "print(new_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loading Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# åŠ è½½ BERT åˆ†è¯å™¨\n",
    "\n",
    "model_name = 'hfl/chinese-roberta-wwm-ext'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# åŠ è½½ BertForSequenceClassification, é¢„è®­ç»ƒ BERT æ¨¡å‹ + é¡¶å±‚çš„çº¿æ€§åˆ†ç±»å±‚ \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name, # å°å†™çš„ 12 å±‚é¢„è®­ç»ƒæ¨¡å‹\n",
    "    num_labels = 2, # åˆ†ç±»æ•° --2 è¡¨ç¤ºäºŒåˆ†ç±»\n",
    "                    # ä½ å¯ä»¥æ”¹å˜è¿™ä¸ªæ•°å­—ï¼Œç”¨äºå¤šåˆ†ç±»ä»»åŠ¡  \n",
    "    output_attentions = False, # æ¨¡å‹æ˜¯å¦è¿”å› attentions weights.\n",
    "    output_hidden_states = False, # æ¨¡å‹æ˜¯å¦è¿”å›æ‰€æœ‰éšå±‚çŠ¶æ€.\n",
    ")\n",
    "\n",
    "# åœ¨ gpu ä¸­è¿è¡Œè¯¥æ¨¡å‹\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(21216, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_toks = tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validate the outcome of codebooks inplant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  æåŒ»ç”Ÿï¼Œä¸€ç™¾å¤©äº†ã€‚ç¥æ‚¨å®‰å¥½ã€‚æˆ‘ä»Šå¤©æ—©ç¡ï¼æ™šå®‰\n",
      "Tokenized:  ['æåŒ»ç”Ÿ', 'ï¼Œ', 'ä¸€', 'ç™¾', 'å¤©', 'äº†', 'ã€‚', 'ç¥', 'æ‚¨', 'å®‰å¥½', 'ã€‚', 'æˆ‘', 'ä»Š', 'å¤©', 'æ—©', 'ç¡', 'ï¼', 'æ™š', 'å®‰']\n",
      "Token IDs:  [21129, 8024, 671, 4636, 1921, 749, 511, 4867, 2644, 21138, 511, 2769, 791, 1921, 3193, 4717, 8013, 3241, 2128]\n"
     ]
    }
   ],
   "source": [
    "# è¾“å‡ºåŸå§‹å¥å­\n",
    "print(' Original: ', sentences[3760])\n",
    "\n",
    "# å°†åˆ†è¯åçš„å†…å®¹è¾“å‡º\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[3760]))\n",
    "\n",
    "# å°†æ¯ä¸ªè¯æ˜ å°„åˆ°è¯å…¸ä¸‹æ ‡\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[3760])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  142\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sent in sentences:\n",
    "\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  æåŒ»ç”Ÿï¼Œä¸€ç™¾å¤©äº†ã€‚ç¥æ‚¨å®‰å¥½ã€‚æˆ‘ä»Šå¤©æ—©ç¡ï¼æ™šå®‰\n",
      "Token IDs: tensor([  101, 21129,  8024,   671,  4636,  1921,   749,   511,  4867,  2644,\n",
      "        21138,   511,  2769,   791,  1921,  3193,  4717,  8013,  3241,  2128,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 142\n",
    "# å°†æ•°æ®é›†åˆ†å®Œè¯åå­˜å‚¨åˆ°åˆ—è¡¨ä¸­\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # è¾“å…¥æ–‡æœ¬\n",
    "                        add_special_tokens = True, # æ·»åŠ  '[CLS]' å’Œ '[SEP]'\n",
    "                        max_length = MAX_LEN,           # å¡«å…… & æˆªæ–­é•¿åº¦\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # è¿”å› attn. masks.\n",
    "                        return_tensors = 'pt',     # è¿”å› pytorch tensors æ ¼å¼çš„æ•°æ®\n",
    "                   )\n",
    "    \n",
    "    # å°†ç¼–ç åçš„æ–‡æœ¬åŠ å…¥åˆ°åˆ—è¡¨  \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # å°†æ–‡æœ¬çš„ attention mask ä¹ŸåŠ å…¥åˆ° attention_masks åˆ—è¡¨\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# å°†åˆ—è¡¨è½¬æ¢ä¸º tensor\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# è¾“å‡ºç¬¬ 1 è¡Œæ–‡æœ¬çš„åŸå§‹å’Œç¼–ç åçš„ä¿¡æ¯\n",
    "print('Original: ', sentences[3760])\n",
    "print('Token IDs:', input_ids[3760])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,573 training samples\n",
      "  189 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# å°†è¾“å…¥æ•°æ®åˆå¹¶ä¸º TensorDataset å¯¹è±¡\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# è®¡ç®—è®­ç»ƒé›†å’ŒéªŒè¯é›†å¤§å°\n",
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# æŒ‰ç…§æ•°æ®å¤§å°éšæœºæ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# åœ¨ fine-tune çš„è®­ç»ƒä¸­ï¼ŒBERT ä½œè€…å»ºè®®å°æ‰¹é‡å¤§å°è®¾ä¸º 16 æˆ– 32\n",
    "batch_size = 16\n",
    "\n",
    "# ä¸ºè®­ç»ƒå’ŒéªŒè¯é›†åˆ›å»º Dataloaderï¼Œå¯¹è®­ç»ƒæ ·æœ¬éšæœºæ´—ç‰Œ\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # è®­ç»ƒæ ·æœ¬\n",
    "            sampler = RandomSampler(train_dataset), # éšæœºå°æ‰¹é‡\n",
    "            batch_size = batch_size # ä»¥å°æ‰¹é‡è¿›è¡Œè®­ç»ƒ\n",
    "        )\n",
    "\n",
    "# éªŒè¯é›†ä¸éœ€è¦éšæœºåŒ–ï¼Œè¿™é‡Œé¡ºåºè¯»å–å°±å¥½\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # éªŒè¯æ ·æœ¬\n",
    "            sampler = SequentialSampler(val_dataset), # é¡ºåºé€‰å–å°æ‰¹é‡\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\kidul\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# æˆ‘è®¤ä¸º 'W' ä»£è¡¨ 'æƒé‡è¡°å‡ä¿®å¤\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# è®­ç»ƒ epochsã€‚ BERT ä½œè€…å»ºè®®åœ¨ 2 å’Œ 4 ä¹‹é—´ï¼Œè®¾å¤§äº†å®¹æ˜“è¿‡æ‹Ÿåˆ \n",
    "epochs = 3\n",
    "\n",
    "# æ€»çš„è®­ç»ƒæ ·æœ¬æ•°\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# æ ¹æ®é¢„æµ‹ç»“æœå’Œæ ‡ç­¾æ•°æ®æ¥è®¡ç®—å‡†ç¡®ç‡\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # å››èˆäº”å…¥åˆ°æœ€è¿‘çš„ç§’\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # æ ¼å¼åŒ–ä¸º hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:06:27 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.289748</td>\n",
       "      <td>0.884215</td>\n",
       "      <td>0:02:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.240789</td>\n",
       "      <td>0.276768</td>\n",
       "      <td>0.889423</td>\n",
       "      <td>0:02:07</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.168861</td>\n",
       "      <td>0.329575</td>\n",
       "      <td>0.889423</td>\n",
       "      <td>0:02:07</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  Training Loss  Valid. Loss  Valid. Accur. Training Time  \\\n",
       "0      1       0.370054     0.289748       0.884215       0:02:06   \n",
       "1      2       0.240789     0.276768       0.889423       0:02:07   \n",
       "2      3       0.168861     0.329575       0.889423       0:02:07   \n",
       "\n",
       "  Validation Time  \n",
       "0         0:00:02  \n",
       "1         0:00:02  \n",
       "2         0:00:02  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingstatsdf = pd.DataFrame(training_stats)\n",
    "trainingstatsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.3700542914115691,
          0.2407885736237014,
          0.16886055458287177
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Valid. Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.2897481520970662,
          0.27676781204839546,
          0.3295746725052595
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Valid. Accur.",
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.8842147435897436,
          0.889423076923077,
          0.889423076923077
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and Validation Loss",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Accuracy",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training history of Whaling Wall Model"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Training and Validation Loss', 'Validation Accuracy'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=trainingstatsdf['epoch'], y=trainingstatsdf['Training Loss'], mode='lines+markers', name='Training Loss'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=trainingstatsdf['epoch'], y=trainingstatsdf['Valid. Loss'], mode='lines+markers', name='Valid. Loss'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=trainingstatsdf['epoch'], y=trainingstatsdf['Valid. Accur.'], mode='lines+markers', name='Valid. Accur.'), row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='Training history of Whaling Wall Model', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/whaling_wall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/whaling_wall\\\\tokenizer_config.json',\n",
       " './model_save/whaling_wall\\\\special_tokens_map.json',\n",
       " './model_save/whaling_wall\\\\vocab.txt',\n",
       " './model_save/whaling_wall\\\\added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# æ¨¡å‹å­˜å‚¨åˆ°çš„è·¯å¾„\n",
    "output_dir = './model_save/whaling_wall'\n",
    "\n",
    "# ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# ä½¿ç”¨ `save_pretrained()` æ¥ä¿å­˜å·²è®­ç»ƒçš„æ¨¡å‹ï¼Œæ¨¡å‹é…ç½®å’Œåˆ†è¯å™¨\n",
    "# å®ƒä»¬åç»­å¯ä»¥é€šè¿‡ `from_pretrained()` åŠ è½½\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # è€ƒè™‘åˆ°åˆ†å¸ƒå¼/å¹¶è¡Œï¼ˆdistributed/parallelï¼‰è®­ç»ƒ\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"LiwenliangSampleAll.csv\",names=['index', 'sentence', '0', 'label','2','3'])\n",
    "df = df.drop(['index','0','2','3'],axis=1)\n",
    "df = df.drop(df.index[0])\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 6,024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\kidul\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning:\n",
      "\n",
      "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "\n",
    "# æ‰“å°æ•°æ®é›†å¤§å°\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "# å°†æ•°æ®é›†è½¬æ¢ä¸ºåˆ—è¡¨\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# åˆ†è¯ã€å¡«å……æˆ–æˆªæ–­\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 6,024 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "# ä¾ç„¶æ˜¯è¯„ä¼°æ¨¡å¼\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# é¢„æµ‹\n",
    "for batch in prediction_dataloader:\n",
    "  # å°†æ•°æ®åŠ è½½åˆ° gpu ä¸­\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # ä¸éœ€è¦è®¡ç®—æ¢¯åº¦\n",
    "  with torch.no_grad():\n",
    "      # å‰å‘ä¼ æ’­ï¼Œè·å–é¢„æµ‹ç»“æœ\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # å°†ç»“æœåŠ è½½åˆ° cpu ä¸­\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # å­˜å‚¨é¢„æµ‹ç»“æœå’Œ labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "dataframe_logits_lables = pd.DataFrame({'logits':predictions,'labels':true_labels})\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ª batch çš„ MCC\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # è®¡ç®—è¯¥ batch çš„ MCC  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)\n",
    "\n",
    "dataframe1 = pd.DataFrame({'MCC':matthews_set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Matthews Corr. Coef Score of model is:  0.8338\n"
     ]
    }
   ],
   "source": [
    "print('Average Matthews Corr. Coef Score of model is: ',dataframe1['MCC'].mean().round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Batch=%{x}<br>MCC=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376
         ],
         "xaxis": "x",
         "y": [
          1,
          1,
          1,
          1,
          0.8783100656536799,
          1,
          1,
          0.7867957924694432,
          1,
          0.6546536707079771,
          0.8783100656536799,
          0.8703882797784892,
          0.8703882797784892,
          0.7867957924694432,
          1,
          1,
          1,
          0.7453559924999299,
          0.8320502943378436,
          0.8563488385776753,
          0.8703882797784892,
          0.8563488385776753,
          0.6546536707079772,
          0.8563488385776753,
          0.7867957924694432,
          0.8703882797784892,
          0.8320502943378436,
          0.8703882797784892,
          0.8783100656536799,
          1,
          0.674199862463242,
          1,
          0.8563488385776753,
          0.746031746031746,
          0.7777777777777778,
          0.674199862463242,
          0.8563488385776753,
          1,
          0.8563488385776753,
          1,
          0.5918640302493726,
          1,
          0.6831300510639733,
          1,
          0.8563488385776753,
          1,
          1,
          0.7453559924999299,
          0.7125253031944253,
          0.8703882797784892,
          0.7777777777777778,
          0.674199862463242,
          1,
          1,
          0.7644707871564383,
          0.7453559924999299,
          1,
          0.6666666666666666,
          1,
          0.8703882797784892,
          1,
          0.7745966692414834,
          0.8819171036881969,
          0.8703882797784892,
          0.7867957924694432,
          0.8563488385776753,
          0.8563488385776753,
          0.6546536707079772,
          0.8563488385776753,
          0.7745966692414834,
          1,
          0.7090909090909091,
          0.7453559924999299,
          0.7644707871564383,
          0.8563488385776753,
          0.674199862463242,
          0.5606119105813882,
          1,
          0.8320502943378436,
          1,
          0.8563488385776753,
          0.8320502943378436,
          0.6831300510639732,
          1,
          0.8563488385776753,
          0.8703882797784892,
          0.7125253031944253,
          1,
          1,
          1,
          1,
          0.7453559924999299,
          1,
          1,
          0.7453559924999299,
          1,
          0.6546536707079771,
          0.7125253031944253,
          0.53748384988657,
          0.8563488385776753,
          1,
          1,
          0.7745966692414834,
          1,
          0.8563488385776753,
          1,
          0.8563488385776753,
          0.8703882797784892,
          0.75,
          0.8703882797784892,
          0.75,
          1,
          1,
          0.8563488385776753,
          1,
          0.6546536707079771,
          1,
          0.5449492609130661,
          0.8703882797784892,
          0.8563488385776753,
          0.75,
          0.8563488385776753,
          0.7644707871564383,
          0.8563488385776753,
          0.8783100656536799,
          0.8703882797784892,
          1,
          0.8320502943378436,
          0.8320502943378436,
          1,
          1,
          0.7745966692414834,
          1,
          0.7644707871564383,
          0.8783100656536799,
          0.6180700462007377,
          1,
          1,
          1,
          0.746031746031746,
          1,
          0.5238095238095238,
          0.7777777777777778,
          0.6831300510639732,
          0.7745966692414834,
          0.8563488385776753,
          0.7125253031944253,
          0.7453559924999299,
          1,
          0.4472135954999579,
          0.6201736729460423,
          0.8703882797784892,
          0.8703882797784892,
          1,
          0.4472135954999579,
          0.629940788348712,
          1,
          0.6546536707079771,
          1,
          0.5238095238095238,
          0.7333333333333333,
          0.8783100656536799,
          0.7777777777777778,
          0.6,
          1,
          0.7644707871564383,
          0.8703882797784892,
          0.674199862463242,
          0.8783100656536799,
          0.6180700462007377,
          0.6666666666666666,
          0.5918640302493726,
          0.8320502943378436,
          1,
          0.8703882797784892,
          1,
          0.8783100656536799,
          0.75,
          0.8783100656536799,
          1,
          1,
          0.746031746031746,
          0.8703882797784892,
          0.6546536707079771,
          0.8703882797784892,
          0.8819171036881969,
          0.8819171036881969,
          0.6831300510639732,
          0.6180700462007377,
          0.6180700462007377,
          1,
          0.8783100656536799,
          0.8703882797784892,
          0.42289003161103106,
          0.8783100656536799,
          1,
          1,
          0.8703882797784892,
          0.8703882797784892,
          1,
          1,
          0.4472135954999579,
          1,
          0.8783100656536799,
          0.75,
          0.8783100656536799,
          1,
          0.5897435897435898,
          0.8563488385776753,
          1,
          0.8819171036881969,
          1,
          1,
          0.8819171036881969,
          0.8819171036881969,
          0.674199862463242,
          0.6180700462007377,
          1,
          0.6201736729460423,
          0.7867957924694432,
          0.7867957924694432,
          0.746031746031746,
          1,
          0.7777777777777778,
          0.8563488385776753,
          0.8703882797784892,
          0.8819171036881969,
          0.8703882797784892,
          0.8703882797784892,
          1,
          0.8563488385776753,
          1,
          0.8320502943378436,
          0.7867957924694432,
          1,
          0,
          0,
          0.5918640302493726,
          0.8703882797784892,
          0.7867957924694432,
          1,
          0.5606119105813882,
          0.8320502943378436,
          0.7333333333333333,
          0.7125253031944253,
          0.7745966692414834,
          0.8783100656536799,
          0.7453559924999299,
          0.7125253031944253,
          0.8783100656536799,
          0.8703882797784892,
          0.8819171036881969,
          1,
          1,
          0.8819171036881969,
          0.7644707871564383,
          0.7453559924999299,
          0.6831300510639733,
          0.8703882797784892,
          0.7125253031944253,
          0.8320502943378436,
          1,
          1,
          0.629940788348712,
          0.8563488385776753,
          0.6180700462007377,
          0.8783100656536799,
          0.8320502943378436,
          0.6201736729460423,
          0.8563488385776753,
          0.7090909090909091,
          0.6546536707079772,
          0.8783100656536799,
          0.7777777777777778,
          0.8320502943378436,
          0.7125253031944253,
          0.363696483726654,
          0.7867957924694432,
          0.6546536707079772,
          1,
          1,
          0.7453559924999299,
          0.7125253031944253,
          0.8320502943378436,
          1,
          0.4472135954999579,
          0.7453559924999299,
          0.8783100656536799,
          0.8320502943378436,
          0.8783100656536799,
          0.5773502691896258,
          0.674199862463242,
          1,
          1,
          1,
          0.8703882797784892,
          1,
          0.8563488385776753,
          0.6546536707079772,
          0.7125253031944253,
          1,
          0.8563488385776753,
          1,
          0.8563488385776753,
          0.8563488385776753,
          1,
          0.4879500364742666,
          0.6546536707079772,
          0.7125253031944253,
          1,
          0.7125253031944253,
          0.8563488385776753,
          0.8703882797784892,
          1,
          0.7453559924999299,
          1,
          0.8703882797784892,
          0.7125253031944253,
          0.7453559924999299,
          0.8819171036881969,
          0.8783100656536799,
          1,
          0.7867957924694432,
          0.8783100656536799,
          0.7644707871564383,
          0.8320502943378436,
          0.8320502943378436,
          0.8563488385776753,
          0.8563488385776753,
          0.8783100656536799,
          1,
          1,
          1,
          0.7745966692414834,
          1,
          0.8563488385776753,
          1,
          0.8563488385776753,
          1,
          1,
          0.8320502943378436,
          0.7867957924694432,
          0.8320502943378436,
          0.7125253031944253,
          1,
          0.8783100656536799,
          0.8819171036881969,
          1,
          0.7453559924999299,
          1,
          1,
          1,
          0.6831300510639732,
          0.8320502943378436,
          0.8563488385776753,
          0.6546536707079772,
          0.5773502691896258,
          0.8320502943378436,
          0.7867957924694432,
          0.8563488385776753,
          0.8783100656536799,
          1,
          0.6831300510639733,
          1,
          0.8819171036881969,
          0.7125253031944253,
          0.4879500364742666,
          0.8320502943378436,
          0.8703882797784892,
          0.8320502943378436,
          0.8563488385776753,
          0.8703882797784892,
          1,
          0.8320502943378436,
          0.6546536707079772,
          0.5606119105813882,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "MCC Score per Batch"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Batch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "MCC"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# åˆ›å»ºæŸ±çŠ¶å›¾æ¥æ˜¾ç¤ºæ¯ä¸ª batch çš„ MCC åˆ†æ•°\n",
    "import plotly.express as px\n",
    "bar = px.bar(x=list(range(len(matthews_set))), y=matthews_set, labels={'x':'Batch', 'y':'MCC'}, title='MCC Score per Batch')\n",
    "bar.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prediction Practical Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "device = 'cuda:0'\n",
    "model = model.to(device)\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\kidul\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning:\n",
      "\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "sentence = []\n",
    "rate = []\n",
    "for i in range(1,len(df['sentence'])):\n",
    "    pipelist = pipe(df['sentence'][i])\n",
    "    label.append(pipelist[0]['label'])\n",
    "    sentence.append(df['sentence'][i])\n",
    "    rate.append(pipelist[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>åŸ‹å¤´äº‹ä¸šä¾¿ä»¤å¤§å®¶å¥½è¿‡</td>\n",
       "      <td>0.995447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>è‡´æ•¬</td>\n",
       "      <td>0.992313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>ä½ å¥½æåŒ»ç”Ÿ å‡ å¤©æ²¡æ¥çœ‹ä½ å•¦ æ™šå®‰ğŸ’¤</td>\n",
       "      <td>0.995290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>ç–«æƒ…æœŸé—´å”¯ä¸€ä¸€ä¸ªè®©æˆ‘ç‰µè‚ æŒ‚è‚šç¥ˆç¦çš„äººï¼ŒæåŒ»ç”Ÿï¼Œäººæ°‘ä¸ä¼šå¿˜è®°ä½ ï¼Œå‹‹ç« ç»™ä½ ï¼Œå…¨ä¸–ç•Œçš„å¹¸ç¦ç»™ä½ çš„å®¶äººã€‚</td>\n",
       "      <td>0.987428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>æåŒ»ç”ŸåšæŒä½ï¼ŒåŠ æ²¹å•ŠğŸ™</td>\n",
       "      <td>0.990866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>ç¼…æ€€</td>\n",
       "      <td>0.991868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>ä»Šå¤©çœŸæ˜¯åœ¨å®¶è¶³è¶³èººäº†ä¸€å¤©</td>\n",
       "      <td>0.993798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>ç”Ÿæ—¥å¿«ä¹ğŸ‚</td>\n",
       "      <td>0.993732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>æ™šå®‰ï¼ŒæåŒ»ç”Ÿ</td>\n",
       "      <td>0.996489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>æ—¶é—´çœŸå¿«å•Šï¼Œå—¨æåŒ»ç”Ÿä¸¤å¹´äº†å“ã€‚æƒ³èµ·ä½ ç¦»å¼€çš„é‚£æ®µæ—¶é—´ä»–ä»¬ï¼Œå¦‚ä»Šä»–ä»¬è¿˜æ˜¯é‚£æ ·ã€‚</td>\n",
       "      <td>0.990442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6023 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                          sentence      rate\n",
       "0     LABEL_0                                        åŸ‹å¤´äº‹ä¸šä¾¿ä»¤å¤§å®¶å¥½è¿‡  0.995447\n",
       "1     LABEL_1                                                è‡´æ•¬  0.992313\n",
       "2     LABEL_1                                 ä½ å¥½æåŒ»ç”Ÿ å‡ å¤©æ²¡æ¥çœ‹ä½ å•¦ æ™šå®‰ğŸ’¤  0.995290\n",
       "3     LABEL_1  ç–«æƒ…æœŸé—´å”¯ä¸€ä¸€ä¸ªè®©æˆ‘ç‰µè‚ æŒ‚è‚šç¥ˆç¦çš„äººï¼ŒæåŒ»ç”Ÿï¼Œäººæ°‘ä¸ä¼šå¿˜è®°ä½ ï¼Œå‹‹ç« ç»™ä½ ï¼Œå…¨ä¸–ç•Œçš„å¹¸ç¦ç»™ä½ çš„å®¶äººã€‚  0.987428\n",
       "4     LABEL_1                                       æåŒ»ç”ŸåšæŒä½ï¼ŒåŠ æ²¹å•ŠğŸ™  0.990866\n",
       "...       ...                                               ...       ...\n",
       "6018  LABEL_1                                                ç¼…æ€€  0.991868\n",
       "6019  LABEL_0                                      ä»Šå¤©çœŸæ˜¯åœ¨å®¶è¶³è¶³èººäº†ä¸€å¤©  0.993798\n",
       "6020  LABEL_1                                             ç”Ÿæ—¥å¿«ä¹ğŸ‚  0.993732\n",
       "6021  LABEL_1                                            æ™šå®‰ï¼ŒæåŒ»ç”Ÿ  0.996489\n",
       "6022  LABEL_1             æ—¶é—´çœŸå¿«å•Šï¼Œå—¨æåŒ»ç”Ÿä¸¤å¹´äº†å“ã€‚æƒ³èµ·ä½ ç¦»å¼€çš„é‚£æ®µæ—¶é—´ä»–ä»¬ï¼Œå¦‚ä»Šä»–ä»¬è¿˜æ˜¯é‚£æ ·ã€‚  0.990442\n",
       "\n",
       "[6023 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe2 = pd.DataFrame({'label':label,'sentence':sentence,'rate':rate})\n",
    "display(dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6023.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.952533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.098038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.974529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.992103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rate\n",
       "count  6023.000000\n",
       "mean      0.952533\n",
       "std       0.098038\n",
       "min       0.500302\n",
       "25%       0.974529\n",
       "50%       0.992103\n",
       "75%       0.995399\n",
       "max       0.997876"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe2.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
