{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from time import sleep\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_time(v_str):\n",
    "    \"\"\"转换GMT时间为标准格式\"\"\"\n",
    "    GMT_FORMAT = '%a %b %d %H:%M:%S +0800 %Y'\n",
    "    timeArray = datetime.datetime.strptime(v_str, GMT_FORMAT)\n",
    "    ret_time = timeArray.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return ret_time\n",
    "\n",
    "\n",
    "def tran_gender(gender_tag):\n",
    "    \"\"\"转换性别\"\"\"\n",
    "    if gender_tag == 'm':\n",
    "        return '男'\n",
    "    elif gender_tag == 'f':\n",
    "        return '女'\n",
    "    else:  # -1\n",
    "        return '未知'\n",
    "\n",
    "\n",
    "def get_comments(v_weibo_ids, v_comment_file, v_max_page):\n",
    "    \"\"\"\n",
    "    爬取微博评论\n",
    "    :param v_weibo_id: 微博id组成的列表\n",
    "    :param v_comment_file: 保存文件名\n",
    "    :param v_max_page: 最大页数\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for weibo_id in v_weibo_ids:\n",
    "        # 初始化max_id\n",
    "        max_id = '0'\n",
    "        # 爬取前n页，可任意修改\n",
    "        for page in range(1, v_max_page + 1):\n",
    "            wait_seconds = random.uniform(0, 0.3)  # 等待时长秒\n",
    "            print('开始等待{}秒'.format(wait_seconds))\n",
    "            sleep(wait_seconds)  # 随机等待\n",
    "            print('开始爬取第{}页'.format(page))\n",
    "            if page == 1:  # 第一页，没有max_id参数\n",
    "                url = 'https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id_type=0'.format(weibo_id, weibo_id)\n",
    "            else:  # 非第一页，需要max_id参数\n",
    "                if str(max_id) == '0':  # 如果发现max_id为0，说明没有下一页了，break结束循环\n",
    "                    print('max_id is 0, break now')\n",
    "                    break\n",
    "                url = 'https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id_type=0&max_id={}'.format(weibo_id,\n",
    "                                                                                                        weibo_id,\n",
    "                                                                                                        max_id)\n",
    "            # 发送请求\n",
    "            # ua = UserAgent(verify_ssl=False)\n",
    "            headers = {\n",
    "                \"User-Agent\" : ua.random,\n",
    "                # 如果cookie失效，会返回-100响应码\n",
    "                \"cookie\": \"SUB=_2A25JKrelDeRhGeFM4lsX-CvNyDSIHXVq1NntrDV6PUJbkdCOLXLxkW1NQIXiGkc5dNwEnwQHRYnGs-GEnLJDF1rR; __bid_n=18756c63dd92834b5b4207; WEIBOCN_FROM=1110006030; FPTOKEN=annfkthMVrLSJy9H1gl8UEURF1sdqaHcMvy9VuyvKMJWLsK4PkGPvVBZglRKaOSQ57G1WIUuYDkcxSs3ESIqZtagIeG7ybxSO654lqzUXVvPPfg9aYiWQTYeWNQU9g6qHTPcyHa8VxuGkvOYjtYeifX8MUxU2SAq6X4lSFWwDp1klL/kyerELCQYnjjiCjipCb+VQBGcuDIKejxTYw3t79dMpS7mKc6t6mwLk2DJvSsXIQlAX4Qpa3v6+wgdrp+JJ57dbXOshvLZHI7JmUHgn3kXgGKiZZrHrxRBcTtRRcCvsBms0ksv5F7p1LqLO9rsdUem0Wp4g6yMmzciCf7LhfmHlRdVRHVNE2V/1x5p3ODhr1fD/2/VzCf+iESkpfJ67Ldd9IG2GO1okN8TbARv7A==|wjUI+Jie8RfKZdbVEcGkve5Ebn++htWccauujD1FGTU=|10|7f2e7730190fcf989106da3cda16e6b2; _T_WM=21494111673; XSRF-TOKEN=a30581; MLOGIN=1; M_WEIBOCN_PARAMS=uicode%3D20000174\",\n",
    "                \"accept\": \"application/json, text/plain, */*\",\n",
    "                \"accept-encoding\": \"gzip, deflate, br\",\n",
    "                \"accept-language\": \"zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "                \"referer\": \"https://m.weibo.cn/detail/{}\".format(weibo_id),\n",
    "                \"x-requested-with\": \"XMLHttpRequest\",\n",
    "                \"mweibo-pwa\": '1',\n",
    "            }\n",
    "            print(url)\n",
    "            r = requests.get(url, headers=headers)  # 发送请求\n",
    "            print(r.status_code)  # 查看响应码\n",
    "            print(r.json())  # 查看响应内容\n",
    "            if r.json() == {'ok': 0}:\n",
    "                max_id = int(max_id) - 1000000000\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    max_id = r.json()['data']['max_id']  # 获取max_id给下页请求用\n",
    "                    datas = r.json()['data']['data']\n",
    "                except Exception as e:\n",
    "                    print('excepted: ' + str(e))\n",
    "                    continue\n",
    "            try:\n",
    "                page_list = []  # 评论页码\n",
    "                id_list = []  # 评论id\n",
    "                text_list = []  # 评论内容\n",
    "                time_list = []  # 评论时间\n",
    "                like_count_list = []  # 评论点赞数\n",
    "                source_list = []  # 评论者IP归属地\n",
    "                user_name_list = []  # 评论者姓名\n",
    "                user_id_list = []  # 评论者id\n",
    "                user_gender_list = []  # 评论者性别\n",
    "                follow_count_list = []  # 评论者关注数\n",
    "                followers_count_list = []  # 评论者粉丝数\n",
    "                for data in datas:\n",
    "                    page_list.append(page)\n",
    "                    id_list.append(data['id'])\n",
    "                    dr = re.compile(r'<[^>]+>', re.S)  # 用正则表达式清洗评论数据\n",
    "                    text2 = dr.sub('', data['text'])\n",
    "                    text_list.append(text2)  # 评论内容\n",
    "                    time_list.append(trans_time(v_str=data['created_at']))\n",
    "                    print(trans_time(v_str=data['created_at']))  # 评论时间\n",
    "                    like_count_list.append(data['like_count'])  # 评论点赞数\n",
    "                    source_list.append(data['source'])  # 评论者IP归属地\n",
    "                    user_name_list.append(data['user']['screen_name'])  # 评论者姓名\n",
    "                    user_id_list.append(data['user']['id'])  # 评论者id\n",
    "                    user_gender_list.append(tran_gender(data['user']['gender']))  # 评论者性别\n",
    "                    follow_count_list.append(data['user']['follow_count'])  # 评论者关注数\n",
    "                    followers_count_list.append(data['user']['followers_count'])  # 评论者粉丝数\n",
    "                df = pd.DataFrame(\n",
    "                    {\n",
    "                        'max_id': max_id,\n",
    "                        '微博id': [weibo_id] * len(time_list),\n",
    "                        '评论页码': page_list,\n",
    "                        '评论id': id_list,\n",
    "                        '评论时间': time_list,\n",
    "                        '评论点赞数': like_count_list,\n",
    "                        '评论者IP归属地': source_list,\n",
    "                        '评论者姓名': user_name_list,\n",
    "                        '评论者id': user_id_list,\n",
    "                        '评论者性别': user_gender_list,\n",
    "                        '评论者关注数': follow_count_list,\n",
    "                        '评论者粉丝数': followers_count_list,\n",
    "                        '评论内容': text_list,\n",
    "                    }\n",
    "                )\n",
    "                if os.path.exists(v_comment_file):  # 如果文件存在，不再设置表头\n",
    "                    header = False\n",
    "                else:  # 否则，设置csv文件表头\n",
    "                    header = True\n",
    "                # 保存csv文件\n",
    "                df.drop_duplicates(subset=['评论id'], inplace=True, keep='first')  # 去重\n",
    "                df.to_csv(v_comment_file, mode='a+', index=False, header=header, encoding='utf_8_sig')\n",
    "                print('结果保存成功:{}'.format(v_comment_file))\n",
    "            except:\n",
    "                print('评论数据异常')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibo_comment_scrape(weibo_id_list, comment_file):\n",
    "    if __name__ == '__main__':  # 指定爬取微博id，可填写多个id\n",
    "        max_page = 1000000  # 爬取最大页数\n",
    "        weibo_id_list = [weibo_id_list]\n",
    "        comment_file = comment_file\n",
    "        # 爬取评论\n",
    "        get_comments(v_weibo_ids=weibo_id_list, v_comment_file=comment_file, v_max_page=max_page)\n",
    "        # 数据清洗-去重\n",
    "        df = pd.read_csv(comment_file)\n",
    "        # 删除重复数据\n",
    "        df.drop_duplicates(subset=['评论id'], inplace=True, keep='first')\n",
    "        # 再次保存csv文件\n",
    "        df.to_csv('去重后_' + comment_file, index=False, encoding='utf_8_sig')\n",
    "        print('数据清洗完成')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Li Wen Liang**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo_comment_scrape('4467107636950632', 'LiwenliangAll.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
